{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b3c683b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "spectral_clustering_from_wasserstein_no_outliers.py\n",
    "---------------------------------------------------\n",
    "Performs spectral clustering on Wasserstein distance matrices\n",
    "and removes a given proportion of outliers before clustering.\n",
    "\n",
    "Steps:\n",
    "1. Load Wasserstein distance matrix\n",
    "2. Compute average distance per language\n",
    "3. Remove top X% outliers (most distant languages)\n",
    "4. Perform spectral clustering (Gaussian kernel + KMeans)\n",
    "5. Save cluster results and 2D spectral embedding plot\n",
    "---------------------------------------------------\n",
    "Author: Samuel Jiang (2025)\n",
    "\"\"\"\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import normalize\n",
    "from numpy.linalg import eigh\n",
    "\n",
    "GROUPS = {\n",
    "    \"objects\": Path(\"/home/njian29/Desktop/wasserstein_matrix_objects.csv\"),\n",
    "    \"ideologies\": Path(\"/home/njian29/Desktop/wasserstein_matrix_ideologies.csv\"),\n",
    "    \"sports\": Path(\"/home/njian29/Desktop/wasserstein_matrix_sports.csv\"),\n",
    "}\n",
    "\n",
    "OUT_DIR = Path(\"/home/njian29/Desktop/spectral_clusters_cleaned\")\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "K = 5             \n",
    "SIGMA = None      \n",
    "OUTLIER_PCT = 0.05\n",
    "\n",
    "def similarity_from_dist(D: np.ndarray, sigma: float | None = None) -> np.ndarray:\n",
    "    if sigma is None:\n",
    "        vals = D[np.triu_indices_from(D, k=1)]\n",
    "        sigma = np.median(vals[vals > 0])\n",
    "        if sigma <= 0 or np.isnan(sigma):\n",
    "            sigma = 1.0\n",
    "    A = np.exp(-(D ** 2) / (2.0 * sigma ** 2))\n",
    "    np.fill_diagonal(A, 0.0)\n",
    "    return A\n",
    "\n",
    "\n",
    "def normalized_graph_laplacian(A: np.ndarray) -> np.ndarray:\n",
    "    d = A.sum(axis=1)\n",
    "    d_inv_sqrt = np.where(d > 0, 1.0 / np.sqrt(d), 0.0)\n",
    "    D_inv_sqrt = np.diag(d_inv_sqrt)\n",
    "    L = np.eye(A.shape[0]) - D_inv_sqrt @ A @ D_inv_sqrt\n",
    "    return L\n",
    "\n",
    "\n",
    "def spectral_embed(L: np.ndarray, k: int) -> np.ndarray:\n",
    "    evals, evecs = eigh(L)\n",
    "    order = np.argsort(evals)\n",
    "    evecs = evecs[:, order]\n",
    "    nontrivial_idx = np.where(evals > 1e-9)[0]\n",
    "    start = nontrivial_idx[0] if nontrivial_idx.size > 0 else 0\n",
    "    U = evecs[:, start:start + k]\n",
    "    U = normalize(U, norm=\"l2\")\n",
    "    return U\n",
    "\n",
    "\n",
    "def spectral_clustering(D: np.ndarray, k: int, sigma: float | None = None):\n",
    "    A = similarity_from_dist(D, sigma)\n",
    "    L = normalized_graph_laplacian(A)\n",
    "    U = spectral_embed(L, k)\n",
    "    km = KMeans(n_clusters=k, n_init=20, random_state=42)\n",
    "    labels = km.fit_predict(U)\n",
    "    return labels, U\n",
    "\n",
    "def remove_outliers(D: np.ndarray, langs: list[str], pct: float):\n",
    "    avg_dist = D.mean(axis=1)\n",
    "    n_remove = int(len(langs) * pct)\n",
    "    if n_remove == 0:\n",
    "        return D, langs\n",
    "\n",
    "    cutoff = np.partition(avg_dist, -n_remove)[-n_remove]\n",
    "    keep_idx = np.where(avg_dist <= cutoff)[0]\n",
    "    removed_idx = np.where(avg_dist > cutoff)[0]\n",
    "\n",
    "    print(f\"[INFO] 去除 {n_remove} 个 outlier (>{pct*100:.1f}%)：\")\n",
    "    for i in removed_idx:\n",
    "        print(f\"    - {langs[i]} (avg dist = {avg_dist[i]:.3f})\")\n",
    "\n",
    "    D_clean = D[np.ix_(keep_idx, keep_idx)]\n",
    "    langs_clean = [langs[i] for i in keep_idx]\n",
    "    return D_clean, langs_clean\n",
    "\n",
    "def main():\n",
    "    for name, path in GROUPS.items():\n",
    "        print(f\"\\n[INFO] 处理 {name}: {path}\")\n",
    "        df = pd.read_csv(path, index_col=0)\n",
    "        langs = df.index.tolist()\n",
    "        D = df.values\n",
    "        D_clean, langs_clean = remove_outliers(D, langs, OUTLIER_PCT)\n",
    "        labels, U = spectral_clustering(D_clean, k=K, sigma=SIGMA)\n",
    "\n",
    "        out_csv = OUT_DIR / f\"clusters_{name}_cleaned.csv\"\n",
    "        pd.DataFrame({\n",
    "            \"Language\": langs_clean,\n",
    "            \"Cluster\": labels\n",
    "        }).sort_values(\"Cluster\").to_csv(out_csv, index=False)\n",
    "        print(f\"[OK] 已保存聚类表: {out_csv}\")\n",
    "\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        plt.style.use(\"seaborn-v0_8-whitegrid\")\n",
    "        scatter = plt.scatter(U[:, 0], U[:, 1], c=labels, cmap=\"tab10\", s=60, edgecolor=\"k\", alpha=0.9)\n",
    "        for i, lang in enumerate(langs_clean):\n",
    "            plt.text(U[i, 0], U[i, 1], lang.replace(\".txt\", \"\"), fontsize=7, ha=\"center\", va=\"center\", alpha=0.8)\n",
    "\n",
    "        plt.title(f\"Spectral Clusters of {name.capitalize()} (Cleaned, k={K})\", fontsize=14, pad=15)\n",
    "        plt.xlabel(\"Spectral Dimension 1\")\n",
    "        plt.ylabel(\"Spectral Dimension 2\")\n",
    "        plt.colorbar(scatter, label=\"Cluster ID\")\n",
    "        plt.tight_layout()\n",
    "\n",
    "        out_fig = OUT_DIR / f\"spectral_clusters_{name}_cleaned.png\"\n",
    "        plt.savefig(out_fig, dpi=300)\n",
    "        plt.close()\n",
    "        print(f\"[OK] 已保存图像: {out_fig}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
